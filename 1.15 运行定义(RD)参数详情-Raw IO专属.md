For parameters specific to file system testing, see [RD parameters for file system testing, detail.](#_bookmark185)

 

The Run Definition parameters specify which of the earlier defined workloads need to be executed, which I/O rates need to be generated, and how long to run the workloads. One Run Definition can result in multiple actual runs, depending on the parameters used.

 

Example: rd=run1,wd=(wd1,wd2),iorate=1000,elapsed=60,interval=5

 

| rd=default                                                   | Sets defaults for all RDs that are entered later.            |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| rd=name                                                      | Unique [name for this Run Definition ](#_bookmark110)(RD).   |
| wd=xx                                                        | [Workload Definitions ](#_bookmark111)to use for this run.   |
| sd=xxx                                                       | [Which SDs to use for this run ](#_bookmark112)(Optional).   |
| curve=(nn,nn,..)                                             | [Data points ](#_bookmark115)to generate when creating a performance curve. |
| stopcurve=n.n                                                | Stop running curve datapoints when response time > n.n ms.   |
| distribution=(x[,variable]                                   | [I/O inter arrival ](#_bookmark120)time calculations: exponential, uniform, ordeterministic. Default exponential. |
| elapsed=nn                                                   | [Elapsed time ](#_bookmark116)for this run in seconds. Default 30 seconds. |
| maxdata=nnn                                                  | Stop the run after nnn bytes have been read or written, e.g. maxdata=200g. Vdbench will stop at the lower of elapsed=and maxdata=. |
| endcmd=cmd                                                   | [Execute command ](#_bookmark55)or script at the end of the last run |
| (for)compratio=nn                                            | Multiple runs for each compression percentage.               |
| (for)hitarea=nn                                              | Multiple runs [for each hit area size.](#_bookmark131)       |
| (for)hpct=nn                                                 | Multiple runs [for each read hit percentage.](#_bookmark128) |
| (for)rdpct=nn                                                | Multiple runs [for each read percentage.](#_bookmark127)     |
| (for)seekpct=nn                                              | Multiple runs [for each seek percentage.](#_bookmark131)     |
| (for)threads=nn                                              | Multiple runs [for each read thread count.](#_bookmark126)   |
| (for)whpct=nn                                                | Multiple runs [for each write hit percentage.](#_bookmark131) |
| (for)xfersize=nn                                             | Multiple runs [for each data transfer size](#_bookmark125).  |
| Most forxxx parameters can just be abbreviated to their regular name, e.g. xfersize=(..,..) |                                                              |
|                                                              |                                                              |
| interval=nn                                                  | [Reporting interval ](#_bookmark117)in seconds. Default 'min(elapsed/2,60)' |
| iorate=(nn,nn,nn,…)                                          | One or more [I/O rates.](#_bookmark113)                      |
| iorate=curve                                                 | Create a [performance curve.](#_bookmark114)                 |
| iorate=max                                                   | Run an [uncontrolled ](#_bookmark113)workload.               |
| iorate=(nn,ss,nn,ss,…)                                       | nn,ss: pairs of I/O rates and seconds of duration for this I/Orate. See also ['distribution=variable'.](#_bookmark121) |
| mount=xxx                                                    | See [HD mount parameter](#_bookmark78)                       |
|                                                              |                                                              |
| openflags=xxxx                                               | [Pass specific flags ](#_bookmark92)when opening a lun or file |
| pause=nn                                                     | [Sleep 'nn' seconds ](#_bookmark122)before starting next run. |



 

| replay=(filename,…) | File name used for [Swat I/O replay ](#_bookmark151)(file 'flatfile.bin' fromSwat) |
| ------------------- | ------------------------------------------------------------ |
| startcmd=cmd        | [Execute command ](#_bookmark55)or script at the beginning of the first run |
| warmup=nn           | Override [warmup period.](#_bookmark118)                     |

 

#### **1.15.1** ***\*'rd=name': Run\**** ***\*Name\****

 

'rd=*name*' defines a unique name for this run. Run names are used in output reports to identify which run is reported.

When you specify ‘default’ as the RD name, the values entered will be used as default for all SD parameters that follow.

 

 

 

#### **1.15.2** ***\*'wd=': Names of Workloads to\**** ***\*Run\****

 

'wd=' identifies workloads to run. Specify a single workload as 'wd=wd1' or multiple workloads either by entering them individually 'wd=(wd1,wd2,wd3)', a range 'wd=(wd1-wd3)' or by using a wildcard character: 'wd=wd*'.

The total [skew percentage ](#_bookmark103)specified for all requested workloads must equal 100. Note: When using a WD range, leading zeros are not allowed, e.g. (wd01-wd09)

 

#### **1.15.3** ***\*‘sd=xxx’\****

 

Normally you specify the SDs to be used as part of a Workload Definition (WD) parameter. However, when you specify all workload parameters using the available ‘forxx’ RD options, the WD parameter really is not necessary at all, so you can now specify the SD parameters during the Run Definition.

You can specify both the WD and the SD parameters though. In that case the SD parameters specified here will override the SD parameters used when you defined the WD= workload. If you do not specify the WD parameter, all defaults as currently set for the Workload Definition are used.

 

#### **1.15.4** ***\*'iorate=nn': One or More I/O\**** ***\*rates\****

 

| iorate=100             | Run a workload of 100 I/Os per second                        |
| ---------------------- | ------------------------------------------------------------ |
| iorate=(100,200,…)     | Run a workload of 100 I/Os per second, then 200, etc.        |
| iorate=(100-1000,100)  | Run workloads with I/O rates from 100 to 1000, incremented by100. |
| iorate=curve           | Run a performance curve. See below.                          |
| iorate=max             | Run the maximum **uncontrolled** I/O rate possible. See below. |
| iorate=(nn,ss,nn,ss,…) | nn,ss: pairs of I/O rates and seconds of duration for this I/O rate.See also ['distribution=variable'.](#_bookmark121) |



 

 

 

'iorate=curve': Run a performance curve.

 

· When no skew is requested for any workload involved, determine the maximum possible I/O rate by running 'iorate=max'. After this 'max' run, the target skew for the requested workloads will be set to the skew that was observed. Workloads of 10%, 50%, 70%, 80%, 90% and 100% of the observed maximum I/O rate and skew will be run. Target I/O rates above 100 will be rounded up to 100; I/O rates below 100 will be rounded up to 10. Curve percentages can be overridden using the ['curve='](#_bookmark115) parameter.

· When any skew is requested, do the same, but ***within\*** the requested skew.

· stopcurve=n.n will prevent the next curve datapoints from being run once the average response time reaches n.n milliseconds.

 

'iorate=max': Run the maximum I/O rate possible.

 

· When **no** skew is requested, allow each workload to run as fast as possible without controlling skew. This is called an **uncontrolled** max workload.

**Warning**: File system workloads using fwdrate= are always controlled using a default skew per FSD and FWD.

· When **any** skew is requested, allow all workloads to run as fast as possible ***within\*** the requested skew.

 

During a Vdbench replay run, the I/O rate by default is set to the I/O rate as it is observed in the trace input. This I/O rate is reported on the console and in file *logfile.html*.

If a different I/O rate is requested, the inter-arrival times of all the I/Os found in the trace will be adjusted to allow for the requested change. Note though that a one hour trace replayed at twice the iops will last only 30 minutes.

 

#### **1.15.5** ***\*'curve=nn': Define Data points for\**** ***\*Curve\****

 

The default data points for a performance curve are 10, 50, 70,80, 90, and 100%. To change this, use the curve= parameter. Example: curve=(10-100,10) creates one data point for each 10% of the maximum I/O rate. Target I/O rates above 100 will be rounded up to 100; I/O rates below 100 will be rounded up to 10.

Remember: each data point takes 'elapsed=nn' seconds!

 

#### **1.15.6** ***\*'elapsed=nn: Elapsed\**** ***\*Time\****

 

This parameter specifies the elapsed time in seconds for each run. This value needs to be at least twice the value of the reporting interval below. Each requested workload runs for 'elapsed=' seconds while detailed performance interval statistics are reported every 'interval=' seconds. At the end of a run, a total is reported for all intervals *except* for the first interval (or warmup=nn



 

duration). The requirement to have at least 2 intervals allows us to have at least 1 reporting interval included in the workload total.

See also: [maxdata ](#_bookmark119)and ['format=limited'.](#_bookmark188)

 

Note that if you specify seek=eof your run will stop at the earlier of reaching EOF, or the elapsed time. This means that a seek=eof run for a 10TB lun with elapsed=10 will stop after 10 seconds! In that case, just specify elapsed=100h.

The same of course also is valid when using maxdata=x.

 

#### **1.15.7** ***\*'interval=nn': Reporting\**** ***\*Interval\****

 

This parameter specifies the duration in seconds for each reporting interval. At the end of each reporting interval, all statistics that have been collected are reported.

 

Note: when doing very long runs for instance over the weekend, the amount of detail data reported can become overwhelming. A more reasonable interval duration may be appropriate, for instance 60 seconds. However, if you have a poorly performing storage device that never seems to be able to get to a stable workload I/O rate you may want to choose the lowest reporting interval possible. The longer your reporting interval, the more you will hide possible performance problems.

See also the report=no_sd_detail parameter if you want to limit the amount of output.

 

#### **1.15.8** ***\*‘warmup=nn’: Warmup\**** ***\*period\****

 

By default Vdbench will exclude the first interval from its run totals. The warmup value will cause the first ‘warmup/interval’ intervals to be excluded. Using this parameter also changes the meaning of the ‘elapsed=’ parameter to mean ‘run elapsed= seconds *after* the warmup period completes’.

 

#### **1.15.9** ***\*'maxdata=': stop after nnn\**** ***\*bytes.\****

 

maxdata=, maxdata_read=, max_data_written:

Normally a run terminates after elapsed= seconds. maxdata= will terminate the run after the shorter of elapsed= or maxdata= bytes have been read or written.

Note that the byte count starts AFTER warmup= seconds, and that maxdata is only checked at the end of a reporting interval.

 

This parameter is available both for both raw and file system workloads, with the following difference: for raw workloads, any specified value less than 100 will be used to multiply this value with the total size of all currently used SDs. For instance two SDs, each of 10gb, using maxdata=5 will stop this run after 2*10gb*5=100gb worth of data has been accessed AFTER the warmup period.

Remember though: your elapsed time must be long enough to get this far.



 

#### **1.15.10** ***\*'distribution=xxx': I/O arrival time\**** ***\*distribution\****

 

*distribution=([exponential][uniform][deterministic],[variable],[spike]) distribution=([e][u][d],[variable],[spike])*

 

· Exponential: exponential distribution. Default. In simple terms, an exponential arrival rate is a good distribution to achieve lots of I/O bursts. It is a good method to approximate a large application with many users. An exponential arrival rate is a classic modeling approach to describe a general arrival distribution of independent events. It causes significant queuing to occur even when the device utilization is only 50% busy.

· Uniform: uniform distribution

· Deterministic: deterministic: all I/O is evenly spread out using fixed inter arrival times.

· Variable: changes the meaning of the iorate= parameter, defining a set of pairs, first an I/O rate, then the amount of seconds to use that I/O rate. This causes I/O to generate a variable I/O rate.

· Spike: the I/O for the above mentioned variable I/O rates will be all started together at the beginning of each second instead of them being spread out using the requested exponential or uniform distribution.

 

Example: rd=rd1,…,iorate=(100,10,1000,5,50,10),dist=variable

 

Result: 100 iops for ten seconds, 1000 iops for five seconds, 50 iops for ten seconds and then again 100 iops. Make sure your elapsed time covers your requested amount of seconds.

The total amount of seconds specified may not be more than 3600 seconds.

 

#### **1.15.11** ***\*'pause=nn': Sleep 'nn'\**** ***\*Seconds\****

 

When doing multiple runs, the 'pause=nn' parameter causes Vdbench to go to sleep for 'nn' seconds before it starts the next run. This parameter is ignored for the first run. 'pause=nn' can be used to allow a storage controller some time to catch its breath and complete things like emptying cache.

 

#### **1.15.12** ***\*Workload parameter specification in a Run\**** ***\*Definition.\****

 

The original objective of all the forxxx parameters was to allow a user to override most of all Workload Definition (WD) parameters specified earlier to create complex, varying workloads, like forxfersize=(1k-1m,d).

Once I observed that some users were specifying here frequently just single parameters like forx=16k I realized that this started making the Workload Definition obsolete. Yes, you’ll always need multiple WDs to allow the running of *different concurrent* workloads, but for a workload without any forxxx variations WDs were not really needed anymore.



 

To make life easier for my users I then added the sd= parameter to a Run Definition, and from that point on indeed the WD became obsolete for this type of non-varying run.

The next step then was of course to not even ask you to specify forxfersize=, but just simply xfersize=. Internally of course Vdbench still treats it as a forxxx parameter, but as far as the parameter definition, you can now just specify xfersize=4k.

 

Previous: sd=sd1,lun=/dev/xxx

wd=wd1,sd=*,rdpct=100,xfersize=4k rd=rd1,wd=wd1,iorate=max,elapsed=60,interval=1

 

New (And of course you can still code xfersize=(4k,8k): sd=sd1,lun=/dev/xxx rd=rd1,sd=*,iorate=max,elapsed=60,interval=1,rdpct=100,xfersize=4k

 

 

## **1.15.12.1** ***\*‘sd=xxx’ Specify SDs to\**** ***\*use\****

 

If you did not specify a Workload Definition you may specify the SDs to be used here.

If you use both the sd= and wd= parameters, this will override the SDs specified in the Workload Definition.

 

Three little tricks: sd=single, sd=range and sd=setsofN.

· sd=single: Let's say you have 10 devices you want to test. Just code an SD for each of them, sd1-sd10. Instead of having to specify one Run Definition for each, just code sd=single, and Vdbench will repeat the current RD once for each SD.

· sd=range: To do a test for sd1, then sd1-sd2, then sd1-sd3 etc. code sd=range and Vdbench will take care of it.

· sd=setsofN: Vdbench will create a Run Definition for each set of 'N' randomly selected SDs. If you have 512 drives, sd=single just is too slow. Example: sd=setsof4

 

## **1.15.12.2** ***\*'(for)xfersize=nn': Create '\*******\**for'\**\*** ***\*Loop Using Different Transfer\**** ***\*Sizes\****

 

The 'forxfersize=' parameter is an override for all workload specific xfersize parameters and allows multiple automatic executions of a workload with different data transfer sizes.

 

| forxfersize=4k              | One run with 4k transfer size.                               |
| --------------------------- | ------------------------------------------------------------ |
| forxfersize=(4k,8k,12k,16k) | One run each for 4k, 8k, etc.                                |
| forxfersize=(4k-32k,4k)     | One run each from 4k to 32k in increments of 4k.             |
| forxfersize=(1k-128k,d)     | One run each from 1k to 128k, each time doubling thetransfer size. (1k,2k,4k,8k,etc). |
| forxfersize=(128k,1k,d)     | 'Reverse' double: (128k,64k,32k,etc)                         |

 

See [Order of Execution ](#_bookmark133)for information on the execution order of this parameter.



 

 

 

## **1.15.12.3** ***\*'(for)threads=nn': Create\**** ***\**'for'\**\*** ***\*Loop Using Different Thread\**** ***\*Counts\****

 

The 'forthreads=' parameter is an override for all storage definition specific thread parameters and allows multiple automatic executions of a workload with different numbers of threads.

 

Note: the meaning of this parameter changes when using [SD concatenation. ](#_bookmark135)During SD concatenation this parameter specified the total amount of threads that will be shared by all storage definitions.

 

 

| forthreads=32        | Do one run with 32 threads for each SD.                      |
| -------------------- | ------------------------------------------------------------ |
| forthreads=(1,2,3,4) | Do one run each with 1, 2, 3 and 4 threads.                  |
| forthreads=(1-5,1)   | Do one run each from 1 to 5 threads in increments of one.    |
| forthreads=(1-64,d)  | Do one run each from 1 to 64 threads, each time doubling thethread count. |
| forthreads=(64-1,d)  | 'Reverse' double: (64,32,16,etc)                             |

 

See [Order of Execution ](#_bookmark133)for information on the execution order of this parameter.

 

 

## **1.15.12.4** ***\*'(for)rdpct=nn': Create\**** ***\**'for'\**\*** ***\*Loop Using Different Read Percentages\****

 

The 'forrdpct=' parameter is an override for all workload specific *rdpct* parameters, and allows multiple automatic executions of a workload with different read percentages.

 

| forrdpct=50          | Do one run with 50% reads                                    |
| -------------------- | ------------------------------------------------------------ |
| forrdpct=(10-100,10) | Do one run each with read percentage values ranging from 10to 100 percent, incrementing the read percentage by 10 percent each time. |

 

See [Order of Execution ](#_bookmark133)for information on the execution order of this parameter.

 

 

## **1.15.12.5** ***\*'(for)rhpct=nn': Create\**** ***\**'for'\**\*** ***\*Loop Using Different Read Hit Percentages\****

 

The 'forrhpct=' parameter is an override for all workload specific *rhpct* parameters, and allows multiple automatic executions of a workload with different read hit percentages.

 

| forrhpct=50          | Do one run with 50% read hits                           |
| -------------------- | ------------------------------------------------------- |
| forrhpct=(10-100,10) | Do one run each with read hit percentage values ranging |



 

 ![img](G:\sineio-projects\VdbenchUsersGuide-cn\1.15 运行定义(RD)参数详情-raw IO专属\img\wps43.png)

 

![img](G:\sineio-projects\VdbenchUsersGuide-cn\1.15 运行定义(RD)参数详情-raw IO专属\img\wps44.png)See [Order of Execution ](#_bookmark133)for information on the execution order of this parameter.

 

 

## **1.15.12.6** ***\*'(for)whpct=nn': Create\**** ***\**'for'\**\*** ***\*Loop Using Different Write Hit\**** ***\*Percentages\****

 

The 'forwhpct=' parameter is an override for all workload specific *whpct* parameters, and allows multiple automatic executions of a workload with different write hit percentages.

 

| forwhpct=50          | Do one run with 50% write hits                               |
| -------------------- | ------------------------------------------------------------ |
| forwhpct=(10-100,10) | Do one run each with write hit percentage values ranging from 10 to 100 percent, incrementing the write hitpercentage by 10 percent each time. |

 

See [Order of Execution ](#_bookmark133)for information on the execution order of this parameter.

 

 

## **1.15.12.7** ***\*'(for)seekpct=nn': Create\**** ***\**'for'\**\*** ***\*Loop Using Different Seek Percentages\****

 

The 'forseekpct=' parameter is an override for all workload specific *seekpct* parameters, and allows multiple automatic executions of a workload with different seek percentages.

 

| forseekpct=50           | Do one run with 50% seek                                     |
| ----------------------- | ------------------------------------------------------------ |
| forseekpct =(10-100,10) | Do one run each with seek percentage values ranging from10 to 100 percent, incrementing the seek percentage by 10 percent each time. |

 

See [Order of Execution ](#_bookmark133)for information on the execution order of this parameter.

 

 

## **1.15.12.8** ***\*'(for)hitarea=nn': Create\**** ***\**'for'\**\*** ***\*Loop Using Different Hit Area Sizes\****

 

The 'forhitarea=' parameter is an override for all Storage Definition hit area parameters, and allows multiple automatic executions of a workload with different hit area sizes:

 

| forhitarea=4m              | Do one run with 4MB hit area                                 |
| -------------------------- | ------------------------------------------------------------ |
| forhitarea =(10m-100m,10m) | Do one run each with hit area values ranging from 10MB to 100 MB, incrementing the hit area by 10 MB each time. |



 

See [Order of Execution ](#_bookmark133)for information on the execution order of this parameter.

 

 

## **1.15.12.9** ***\*'(for)compratio=nn': Create\**** ***\**'for'\**\*** ***\*Loop Using Different compression\**** ***\*ratios.\****

The 'forcompratio=' parameter is an override for the compratio= parameter, and allows multiple automatic executions of a workload with different compression ratios.

 

 

## **1.15.12.10** ***\*Order of Execution Using 'for\*******\**xxx\**\******\*'\**** ***\*Parameters\****

 

The order in which the 'forthreads=', 'forxfersize=', 'forrdpct=', 'forrhpct=' , 'forwhpct=', 'forseekpct=' and 'forhitarea=' parameters are found in the input will determine the order in which the requested workloads will be executed.

Treat this as a sequence of embedded 'for' loops. Using 'forthreads=' and 'forxfersize' as an example:

· for (all threads) { for (all xfersizes) { for (all I/O rates) } }	versus

· for (all xfersizes) { for (all threads) { for (all I/O rates) } }	depending on what parameter came first.